{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAaN9/Vq5ocopfvo4O84L+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahYLawrence/Text-Mining-and-Analytics/blob/Task-3/Erisk_T3_dataclear2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs90nN4QVMhg"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "def merge_text_from_csv(csv_folder, txt_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(txt_folder):\n",
        "        os.makedirs(txt_folder)\n",
        "\n",
        "    # Loop through each file in the input folder\n",
        "    for file_name in os.listdir(csv_folder):\n",
        "        if file_name.endswith('.csv'):\n",
        "            csv_file = os.path.join(csv_folder, file_name)\n",
        "            output_file = os.path.join(txt_folder, os.path.splitext(file_name)[0] + '.txt')\n",
        "            merge_text_from_single_csv(csv_file, output_file)\n",
        "\n",
        "def merge_text_from_single_csv(csv_file, output_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        text_data = []\n",
        "        for row in reader:\n",
        "            text_data.append(row['Text'])\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as txtfile:\n",
        "        txtfile.write('\\n'.join(text_data))\n",
        "\n",
        "# Replace 'input_folder' with the path to the folder containing CSV files\n",
        "# Replace 'output_folder' with the path to the folder where you want to save the text files\n",
        "merge_text_from_csv('2022', '2022txt')\n",
        "merge_text_from_csv('2023', '2023txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r 2022txt.zip 2022txt/\n",
        "!zip -r 2023txt.zip 2023txt/\n"
      ],
      "metadata": {
        "id": "Aj_wVXvFaqXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import json\n",
        "\n",
        "def merge_text_and_create_json(csv_folder, txt_folder, json_file):\n",
        "    data = []\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(txt_folder):\n",
        "        os.makedirs(txt_folder)\n",
        "\n",
        "    # Loop through each file in the input folder\n",
        "    for file_name in os.listdir(csv_folder):\n",
        "        if file_name.endswith('.csv'):\n",
        "            csv_file = os.path.join(csv_folder, file_name)\n",
        "            output_file = os.path.join(txt_folder, os.path.splitext(file_name)[0] + '.txt')\n",
        "            text_data = merge_text_from_single_csv(csv_file, output_file)\n",
        "            data.append({\"file_name\": file_name, \"text\": text_data})\n",
        "\n",
        "    # Write the data to the JSON file\n",
        "    with open(json_file, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(data, jsonfile, indent=4)\n",
        "\n",
        "def merge_text_from_single_csv(csv_file, output_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        text_data = []\n",
        "        for row in reader:\n",
        "            text_data.append(row['Text'])\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as txtfile:\n",
        "        txtfile.write('\\n'.join(text_data))\n",
        "\n",
        "    return text_data\n",
        "\n",
        "# Replace 'input_folder' with the path to the folder containing CSV files\n",
        "# Replace 'output_folder' with the path to the folder where you want to save the text files\n",
        "# Replace 'output_json.json' with the desired name for the JSON file\n",
        "merge_text_and_create_json('2022', '2022txt', 'output_json2022.json')\n",
        "merge_text_and_create_json('2023', '2023txt', 'output_json2023.json')\n"
      ],
      "metadata": {
        "id": "_01_k_sMhVP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n"
      ],
      "metadata": {
        "id": "apa1JpAgFakt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import json\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def merge_text_and_create_json(csv_folder, txt_folder, json_file):\n",
        "    data = []\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(txt_folder):\n",
        "        os.makedirs(txt_folder)\n",
        "\n",
        "    # Loop through each file in the input folder\n",
        "    for file_name in os.listdir(csv_folder):\n",
        "        if file_name.endswith('.csv'):\n",
        "            csv_file = os.path.join(csv_folder, file_name)\n",
        "            output_file = os.path.join(txt_folder, os.path.splitext(file_name)[0] + '.txt')\n",
        "            text_data = merge_text_from_single_csv(csv_file, output_file)\n",
        "\n",
        "            # Summarize the text data\n",
        "            summary = summarize_text('\\n'.join(text_data))\n",
        "\n",
        "            # Append the summarized text along with the original text to the data list\n",
        "            data.append({\"file_name\": file_name, \"text\": text_data, \"summary\": summary})\n",
        "\n",
        "    # Write the data to the JSON file\n",
        "    with open(json_file, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(data, jsonfile, indent=4)\n",
        "\n",
        "def merge_text_from_single_csv(csv_file, output_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        text_data = []\n",
        "        for row in reader:\n",
        "            text_data.append(row['Text'])\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as txtfile:\n",
        "        txtfile.write('\\n'.join(text_data))\n",
        "\n",
        "    return text_data\n",
        "\n",
        "def summarize_text(text):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = LsaSummarizer()\n",
        "    summary = summarizer(parser.document, 2)  # Summarize to 2 sentences\n",
        "    return \" \".join([str(sentence) for sentence in summary])\n",
        "\n",
        "# Replace 'input_folder' with the path to the folder containing CSV files\n",
        "# Replace 'output_folder' with the path to the folder where you want to save the text files\n",
        "# Replace 'output_json.json' with the desired name for the JSON file\n",
        "merge_text_and_create_json('2022', '2022txt', 'output_json2022.json')\n",
        "merge_text_and_create_json('2023', '2023txt', 'output_json2023.json')\n"
      ],
      "metadata": {
        "id": "dKlqBJHbE5v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers numpy\n"
      ],
      "metadata": {
        "id": "PBpsN38fIPyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def generate_vectors_from_json(json_file):\n",
        "    # Load SBERT model\n",
        "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "    # Load data from JSON file\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Generate vectors for each text\n",
        "    for entry in data:\n",
        "        text = entry['text']\n",
        "        vectors = generate_vectors(text, model)\n",
        "        entry['vector'] = vectors\n",
        "\n",
        "    # Update JSON file with vectors\n",
        "    with open(json_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=4, default=lambda x: x.tolist())\n",
        "\n",
        "def generate_vectors(texts, model):\n",
        "    return [model.encode(text).tolist() for text in texts]  # Convert numpy array to list\n",
        "\n",
        "# Replace 'json_file_path' with the path to your JSON file\n",
        "json_file_path = 'output_json2022.json'\n",
        "\n",
        "# Generate vectors and update JSON file\n",
        "generate_vectors_from_json(json_file_path)\n"
      ],
      "metadata": {
        "id": "gDgcjxK-IRM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}